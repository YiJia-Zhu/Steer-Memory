#!/usr/bin/env python3
"""
æµ‹è¯•æ‰€æœ‰æ•°æ®é›†çš„offsetåŠŸèƒ½
"""

from data_loader import load_dataset_seal

# æ•°æ®é›†é…ç½®ï¼ˆä¸run_baseline_distributed.pyä¸­çš„DATASET_CONFIGä¸€è‡´ï¼‰
DATASET_CONFIG = {
    'math500': {'train': 100, 'eval': 400, 'total': 500},
    'aime_2024': {'train': 10, 'eval': 20, 'total': 30},
    'aime25': {'train': 10, 'eval': 20, 'total': 30},
    'amc23': {'train': 10, 'eval': 30, 'total': 40},
    'arc-c': {'train': 100, 'eval': 199, 'total': 299},
    'openbookqa': {'train': 100, 'eval': 400, 'total': 500},
}

print('='*80)
print('æµ‹è¯•æ‰€æœ‰æ•°æ®é›†çš„æ•°æ®åˆ†å‰²åŠŸèƒ½')
print('='*80)
print()

all_passed = True
results = []

for dataset_name, config in DATASET_CONFIG.items():
    print(f'ğŸ“Š æµ‹è¯•æ•°æ®é›†: {dataset_name}')
    print('-'*80)
    
    try:
        # åŠ è½½è®­ç»ƒé›†ï¼ˆå‰Nä¸ªæ ·æœ¬ï¼‰
        train_data = load_dataset_seal(
            dataset_name, 
            'datasets', 
            max_examples=config['train'], 
            offset=0
        )
        train_count = len(train_data)
        
        # åŠ è½½æµ‹è¯•é›†ï¼ˆåMä¸ªæ ·æœ¬ï¼‰
        eval_data = load_dataset_seal(
            dataset_name, 
            'datasets', 
            max_examples=config['eval'], 
            offset=config['train']
        )
        eval_count = len(eval_data)
        
        # éªŒè¯æ•°æ®ä¸é‡å¤
        is_different = True
        if train_count > 0 and eval_count > 0:
            is_different = train_data[-1]["question"] != eval_data[0]["question"]
        
        # æ£€æŸ¥ç»“æœ
        train_ok = train_count == config['train']
        eval_ok = eval_count == config['eval']
        total_ok = (train_count + eval_count) == config['total']
        all_ok = train_ok and eval_ok and total_ok and is_different
        
        status = 'âœ…' if all_ok else 'âŒ'
        results.append({
            'dataset': dataset_name,
            'passed': all_ok,
            'train': train_count,
            'eval': eval_count,
            'no_overlap': is_different
        })
        
        print(f'  è®­ç»ƒé›†: {train_count}/{config["train"]} {"âœ…" if train_ok else "âŒ"}')
        print(f'  æµ‹è¯•é›†: {eval_count}/{config["eval"]} {"âœ…" if eval_ok else "âŒ"}')
        print(f'  æ€»è®¡: {train_count + eval_count}/{config["total"]} {"âœ…" if total_ok else "âŒ"}')
        print(f'  æ•°æ®ä¸é‡å¤: {"âœ…" if is_different else "âŒ"}')
        print(f'  ç»“æœ: {status}')
        
        if not all_ok:
            all_passed = False
            
    except Exception as e:
        print(f'  âŒ é”™è¯¯: {str(e)}')
        results.append({
            'dataset': dataset_name,
            'passed': False,
            'train': 0,
            'eval': 0,
            'no_overlap': False
        })
        all_passed = False
    
    print()

# æ‰“å°æ€»ç»“
print('='*80)
print('æµ‹è¯•ç»“æœæ€»ç»“')
print('='*80)
print()

print(f'{"æ•°æ®é›†":<15} {"è®­ç»ƒé›†":<12} {"æµ‹è¯•é›†":<12} {"æ€»è®¡":<10} {"ä¸é‡å¤":<8} {"çŠ¶æ€":<6}')
print('-'*80)

for r in results:
    cfg = DATASET_CONFIG[r['dataset']]
    train_str = f"{r['train']}/{cfg['train']}"
    eval_str = f"{r['eval']}/{cfg['eval']}"
    total_str = f"{r['train']+r['eval']}/{cfg['total']}"
    overlap_str = "âœ…" if r['no_overlap'] else "âŒ"
    status_str = "âœ… PASS" if r['passed'] else "âŒ FAIL"
    
    print(f"{r['dataset']:<15} {train_str:<12} {eval_str:<12} {total_str:<10} {overlap_str:<8} {status_str:<6}")

print()
print('='*80)

if all_passed:
    print('ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åˆ†å‰²åŠŸèƒ½æ­£ç¡®å®ç°ï¼')
else:
    print('âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†æˆ–é…ç½®')

print('='*80)

